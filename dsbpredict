#! /usr/bin/env python

# developed by Michael Reilly github.com/mreilly13

import numpy as np
import subprocess
import sys
import os
import argparse
import gzip
import Parser.parsePDB as parser
from NNModel.init import train
from NNModel.launchModel import test
from NNModel.blackBox import load_model

# directories
cwd = os.getcwd()
raw_fp = "/Data/Raw/"
pdb_fp = "/Data/PDB/"
parsed_fp = "/Data/Parsed/"
graph_fp = "/Out/Graphs/"
test_fp = "/Out/Predictions/"
zip_ext = ".ent.gz"
pdb_ext = ".pdb"
parse_ext = ".csv"
result_ext = ".txt"

# parsing command line arguments
argp = argparse.ArgumentParser()
argp.add_argument("-a", "--all", action="store_true", help="perform entire setup process: download, unzip, and parse the PDB, then train the network")
argp.add_argument("-d", "--download", action="store_true", help="check the PDB for updates, or download the PDB; zipped files are stored in Data/Raw")
argp.add_argument("-u", "--unzip", action="store_true", help="unzip the compressed downloaded PDB files; unzipped files are stored in Data/PDB")
argp.add_argument("-p", "--parse", action="store_true", help="parse the PDB files; output files are stored in Data/Parsed")
argp.add_argument("-t", "--train", action="store_true", help="train the neural network")
argp.add_argument("-e", nargs='*', help="evaluate pdb files")
argp.add_argument("-m", nargs=1, help="name of desired model; will use default model without this argument")
argp.add_argument("--all-residues", action="store_true", help="ignore residue classification on evaluation")
args = argp.parse_args()

# running
if not (args.download or args.all or args.unzip or args.parse or args.train or args.e):
    argp.print_help()
    exit(0)
else:
    os.makedirs(os.path.dirname(cwd + raw_fp), exist_ok=True)
    os.makedirs(os.path.dirname(cwd + pdb_fp), exist_ok=True)
    os.makedirs(os.path.dirname(cwd + parsed_fp), exist_ok=True)
    os.makedirs(os.path.dirname(cwd + test_fp), exist_ok=True)

# download the PDB
if args.download or args.all:
    proc = subprocess.Popen('/bin/bash', text=True, stdin=subprocess.PIPE, stdout=sys.stdout, stderr=sys.stderr)
    proc.communicate('Data/download.sh')

# unzip the downloaded PDB
if args.unzip or args.all:
    zipped = os.listdir(cwd + raw_fp)
    zipped.sort()
    unzipped = os.listdir(cwd + pdb_fp)
    unzipped.sort()
    for pdb in zipped:
        if not pdb.endswith(zip_ext):
            continue
        name = pdb[:pdb.find(zip_ext)]
        fullname = name + pdb_ext
        raw_path = cwd + raw_fp + pdb
        pdb_path = cwd + pdb_fp + fullname
        if not (fullname in unzipped and os.path.getmtime(raw_path) < os.path.getmtime(pdb_path)):
            with gzip.open(raw_path, "rt") as infile:
                content = infile.read()
            print(name, "unzipping")
            with open(pdb_path, "w") as outfile:
                outfile.write(content)
        else:
            print(name, "up to date")

# parse the unzipped .pdb files
if args.parse or args.all:
    zipped = os.listdir(cwd + raw_fp)
    zipped.sort()
    unzipped = os.listdir(cwd + pdb_fp)
    unzipped.sort()
    parsed = os.listdir(cwd + parsed_fp)
    parsed.sort()
    failed_fp = cwd + "/Data/failed.csv"
    open(failed_fp, "a")
    with open(failed_fp, "r+") as f:
        failed = f.readlines()
        for pdb in unzipped:
            name = pdb[:pdb.find(pdb_ext)]
            fullname = name + parse_ext
            raw_path = cwd + raw_fp + name + zip_ext
            pdb_path = cwd + pdb_fp + pdb
            parsed_path = cwd + parsed_fp + fullname
            if not (fullname in parsed and os.path.getmtime(raw_path) < os.path.getmtime(parsed_path)) and name+'\n' not in failed:
                print(name, end=" ")
                errc, data = parser.parse(pdb_path)
                if errc == 1:
                    print("parse failed")
                    f.write(name + '\n')
                elif errc == 2:
                    print("has no trainable disulfide bonds")
                    f.write(name + '\n')
                else:
                    print("parse successful")
                    np.savetxt(parsed_path, data, fmt=parser.csv_format, delimiter=',')
            else:
                print(name, "already parsed")

# train the neural network
if args.train or args.all:
    train()

# evaluate one or more pdb files
if args.e:
    def test_file(argpath, NNModel):
        if argpath.endswith(pdb_ext):
            name = argpath.split('/')[-1]
            name = name.removesuffix(pdb_ext)
            outpath = cwd + test_fp + name + result_ext
            errc, raw = parser.parse(argpath, args.all_residues)
            if errc != 0:
                print(name, "parse failed")
            else:
                print(name, "parse succeeded")
                data = np.array([[i['dist'], i['omega'], i['theta'], i['phi'], i['ssbond'], i['chain1'], i['res1'], i['chain2'], i['res2']] for i in raw])
                results = test(data, name, NNModel)
                print(name, "evaluated")
                support_ss = []
                no_support_ss = []
                for i in range(len(data)):
                    if float(results[i][1]) >= .5:
                        support_ss.append(results[i])
                    else:
                        no_support_ss.append(results[i])
                support_ss.sort(key=lambda x: float(x[0]))
                no_support_ss.sort(key=lambda x: float(x[1]), reverse=True)
                with open(outpath, "w") as f:
                    f.write(f"{name}\n")
                    f.write("\nres 1  res 2  confidence\n\n")
                    for i in support_ss:
                        f.write(f"{i[3]} {i[4]:4} {i[5]} {i[6]:4} {float(i[1]):.4f}\n")
                    f.write("\n")
                    for i in no_support_ss:
                        f.write(f"{i[3]} {i[4]:4} {i[5]} {i[6]:4} {float(i[1]):.4f}\n")
        else:
            print(name, "is not a pdb file")
            
    if args.m:
        NNModel = load_model(args.m[0])
    else:
        NNModel = load_model("YBYF_Model_1_large")
    for arg in args.e:
        argpath = os.path.abspath(arg)
        if os.path.isdir(argpath):
            contents = os.listdir(argpath)
            contents.sort()
            for f in contents:
                test_file(argpath + '/' + f, NNModel)
        else:
            if os.path.exists(argpath):
                test_file(argpath, NNModel)
            else:
                print(arg, "not found")